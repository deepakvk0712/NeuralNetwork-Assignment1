{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network Assignment 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Team Members:\n",
    "* Sushmitha Subramanya Javali\n",
    "* maitreyee gupte\n",
    "* Deepak Vasuki Kashyap\n",
    "* Kaustubh Mane\n",
    "* Drishti Idnani\n",
    "* Kamal Sai Raj K"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Design and build a simple dataset \"X\"  of for character recognition of 10 16x16-pixel images of well-formed typeset (not handwritten) digits 0 through 9  (256 pixels per image) from online exemplars or from the following characters.\n",
    "* For this assignment, choose numerals 0 through 9 inclusive, as shown above\n",
    "* Make one 16x16-pixel image per character from the above array -- image should be black and white only, with no grey values. This will be your dataset for the regular problems. Extra credit will have more characters.\n",
    "* In Step 7 (Documentation), make a nice figure with your digits images laid out in an array format (e.g., 2 rows x 5 col)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Design and develop a single-layer perceptron (SLP) in Python, using libraries such as PyTorch (and, if necessary, Tensor Flow).  Your SLP must function in autoassociative mode (i.e., as an associative memory that accepts an element of \"X\"  (i.e., a 16x16-pixel image) as input, and when the SLP is functioning correctly outputs the same element of \"X\")."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Train your SLP on the 10 images that comprise the dataset developed in Step 1), above.  You will want to test your SLP to ensure it functions correctly as an autoassociative memory before you go on to Step 4.  Document your training results\n",
    "* You get credit for showing your preliminary test results and discussing the number of training epochs (iterations through the backpropagation algorithm), then explaining why you need that many iterations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Test your SLP on the entire dataset that you trained on in Step 3), above -- with no noise introduced into the input dataset, using the following procedure:\n",
    "\n",
    "* Apply your trained SLP in autoassociative mode to the dataset \"X\", collecting output data in a test dataset \"Y\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Perturb your dataset (the 10 images that you developed in Step 1), above) by adding noise, and saving the performance results, so you can display them as described in Step 6."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Display Data from your Tests in Step 5), above, as follows:\n",
    "* Step 6a: Gather your results into a table of Fh and Ffa versus test-image-ID, with one column per each value of the standard deviation\n",
    "* Step 6b: Make a very nice-appearing scatter-plot graph of Fh versus Ffa with each noise standard deviation (stdev) value represented on a logarithmically-scaled abscissa whose values range from 0 to 0.1 in steps of 0.001, and with the Fh and Ffa values represented on the linearly-scaled ordinate whose values range from 0 to 1 in steps of 0.1.  Please label the abscissa as \"Gaussian Noise Level (stdev, at 10 pct xsecn)\" and the ordinate as \"Fh and Ffa\".  The graph should have a title in the frame that says, \"Graph of Fh and Ffa vs. Noise Standard Deviation for noise-corrupted Alphanumeric Imagery (16x16 pixels) for Autoassociative Single-Layer Perceptron\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Document your network parameters and results (e.g., number of weights, number of input and output data values, any assumptions you make about the activation function f that is used for thresholding the network output --- and the configuration of your training set(s).  Documentation should be in a PDF file with one-inch margins and 12-point TimesNewRoman type at 1.5-line spacing, which must be organized as follows:\n",
    "\n",
    "### Title Block = \"CAP 6615 - Neural Networks - Programming Assignment 1 -- Single-Layer Perceptron\", followed by your group members' names and \"Spring Semester 2022\" and \"28 Jan 2022\" (each on a separate line)\n",
    "\n",
    "### Body of Report must contain the following information, denoted by Section Number, as shown below:\n",
    "* Network parameters\n",
    "* Python code for your SLP (and put it in one file with extension .py -- to be turned in to Canvas)\n",
    "* Training set configuration (show images in the training set in a nicely formatted figure)\n",
    "* SLP output results for noiseless input in terms of Fh and Ffa graph (as described in Step 4 above)\n",
    "* Pseudocode and Python code for algorithms you used to compute Fh and Ffa\n",
    "* SLP output results for noise-corrupted input as table and graph of Fh and Ffa (as described in Steps 4 thru 6, above)\n",
    "* Discussion (in detail) of why your perceptron performed the way it did, and how you could improve its performance in future.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extra Credit Section"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8: Build a Two- or Three-Layer Shallow Multilayer Neural Net (SMNN) that functions as an autoassociative memory, and optimize it for classifying the training/test set developed in Step 1 (similar to Steps 2 and 3)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 9: Test Your Optimized SMNN on the Noise-Corrupted Data per Steps 4 through 6) -- This will be easy, because you will have already developed the algorithms and scripts for Fh, Ffa, tabulating, and graphing your results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 10: Add an Appendix to Your Report, in which you present and discuss your SMNN results, in the same way you did for the SLP in Parts 1 through 7 of Step 7), above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
